# Section A10: Baby Language Models

> **Name:** Longhao Lin  
> **Email:** lol008@ucsd.edu  
> **Mentor:** Dr. Alex Warstadt

## Quarter 1 Reflection

### 1. Most Interesting Topic

As of now, most of our work focuses on using existing code/repos for replication and learning about potential approaches to our capstone project. Some topics that I found interesting include training a model from scratch and hyperparameter tuning using Weights and Biases.

### 2. Potential Quarter 2 Investigation

A potential investigation that might be suitable for our capstone project is modification based on an existing model. For example, we could modify the architecture of an existing model to see if there can be an improvement.

### 3. Potential Change to Quarter 1 Approach

As we're primarily focusing on replicating existing work, I think it would also be beneficial if there were some discussion/lessons on how we can code these specific architectures ourselves. I feel this would help build a good foundation in preparation for the Quarter 2 project.

### 4. Other Techniques of Interest

Some other techniques that I would be interested in using would be methods such as architectural modifications such as attention mechanism variants that can potentially improve model performance under a strict data constraint. Another potential technique that I'm also interested in would be combining specific architectures (such as GPT-BERT from previous submission) as a hybrid approach to check if there will be a better result.

---